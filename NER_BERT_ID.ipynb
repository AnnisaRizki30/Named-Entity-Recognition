{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_BERT_ID.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "acc38768d6e541928b6caf82a181aec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_660bf95523514b6cace3881713f49872",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a2cea83034d94e4b9016603694f25f5f",
              "IPY_MODEL_940602ec2c9b4fc4a98f254fa637a653"
            ]
          }
        },
        "660bf95523514b6cace3881713f49872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2cea83034d94e4b9016603694f25f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bd73252594d746e8be8f7dd07681d9eb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2285,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2285,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc164f0034c646b7aeac112ede4e2320"
          }
        },
        "940602ec2c9b4fc4a98f254fa637a653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a986aa00401b40bea19522de9d267dff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.29k/2.29k [00:00&lt;00:00, 2.35kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf317bef6f2f418d8eb805c929ee7423"
          }
        },
        "bd73252594d746e8be8f7dd07681d9eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc164f0034c646b7aeac112ede4e2320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a986aa00401b40bea19522de9d267dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf317bef6f2f418d8eb805c929ee7423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e511ab98c8904326865d6478c0489481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c3af902e8aa7493889784cb6c3c2ca74",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_63d0283f28b8499b861084fe9a602f45",
              "IPY_MODEL_4e3f5e8be2ac4421874c301900d1ae8f"
            ]
          }
        },
        "c3af902e8aa7493889784cb6c3c2ca74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63d0283f28b8499b861084fe9a602f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6dac786690fa4a4eb5fad0d51194e87c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435773041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435773041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb749ed3b91246169ba6866e12992560"
          }
        },
        "4e3f5e8be2ac4421874c301900d1ae8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_acc39389739145238931d45a84f3fe50",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:19&lt;00:00, 22.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b28562d92e504ac1b4f9496bac9124ed"
          }
        },
        "6dac786690fa4a4eb5fad0d51194e87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb749ed3b91246169ba6866e12992560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acc39389739145238931d45a84f3fe50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b28562d92e504ac1b4f9496bac9124ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06e5f3939487493fb74ecda0d439186e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cf951285060949b0b0a8e31ffbb0d051",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c7213bbe161140f4ad2554152f7442d2",
              "IPY_MODEL_10d0d34cec8f4017a636612e3f49d73e"
            ]
          }
        },
        "cf951285060949b0b0a8e31ffbb0d051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7213bbe161140f4ad2554152f7442d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_17bbd3a08a6f4aa5a8420a4c1e22a46c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20a63180826b4ad9892cee9434e3ac1f"
          }
        },
        "10d0d34cec8f4017a636612e3f49d73e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4773f274f20645a7b72ade09f25b544c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 126kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42bf6d41ea864661b02d7771dd7a78be"
          }
        },
        "17bbd3a08a6f4aa5a8420a4c1e22a46c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20a63180826b4ad9892cee9434e3ac1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4773f274f20645a7b72ade09f25b544c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42bf6d41ea864661b02d7771dd7a78be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "806AYKX5bemJ"
      },
      "source": [
        "**Seqeval** is a Python framework for evaluation of sequence labeling. seqeval can evaluate the performance of chunking tasks like named entity recognition, part-of-speech tagging, semantic role labeling and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y4WxMG-EQbP",
        "outputId": "d6e30c9e-e822-496f-d64a-f7ab9abdecfc"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 10 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 20 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 30 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=d94ac9a7222424da793681930ff3b0555eec0407bd16097ba0fa8e37b68f1b9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKipOU-MGZhf",
        "outputId": "7efb1a1e-4584-48b1-d8dc-60370767b6cb"
      },
      "source": [
        "# Install transformers module for NER process needs using BERT transformer\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.6 MB 6.8 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895 kB 55.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3 MB 52.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 636 kB 74.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDc7cFs7b_tq"
      },
      "source": [
        "# **IMPORT NEEDED MODULE**\n",
        "\n",
        "Modules for model evaluation purposes:\n",
        "* from seqeval.metrics import f1_score\n",
        "* from seqeval.metrics import classification_report accuracy_score,f1_score\n",
        "\n",
        "Modules/libraries for deep learning/transfer learning models:\n",
        "* import torch.nn.functional as F\n",
        "* import torch\n",
        "* from torch.optim import Adam \n",
        "* from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler \n",
        "* from keras.preprocessing.sequence import pad_sequences\n",
        "* from transformers import BertTokenizer, BertConfig\n",
        "* from transformers import BertForTokenClassification, AdamW\n",
        "* from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "Module for dataset sharing:\n",
        "* from sklearn.model_selection import train_test_split\n",
        "\n",
        "Module to display progress bar:\n",
        "* from tqdm import tqdm,trange\n",
        "\n",
        "Module for graphic visualization purposes:\n",
        "* import matplotlib.pyplot as plt\n",
        "* import seaborn as sns\n",
        "\n",
        "Module for time calculation purposes:\n",
        "* import time\n",
        "* import datetime\n",
        "\n",
        "Modules for data manipulation purposes:\n",
        "* import pandas as pd\n",
        "* import math\n",
        "* import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RmUE7D8Gg-J"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import time\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "from seqeval.metrics import f1_score\n",
        "from seqeval.metrics import classification_report,accuracy_score,f1_score\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm,trange\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "from transformers import BertForTokenClassification, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhO3sv7AGlce"
      },
      "source": [
        "header_names = ['Word', 'Tag']\n",
        "df1 = pd.read_csv(\"train_corrected.txt\",sep='\\t', names=header_names)\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4JDTNxxuVof"
      },
      "source": [
        "header_names = ['Word', 'Tag']\n",
        "df2 = pd.read_csv(\"test_corrected.txt\", sep='\\t', quoting=3, names=header_names)\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyFvy0J1uvaz"
      },
      "source": [
        "header_names = ['Word', 'Tag']\n",
        "df3 = pd.read_csv(\"valid_corrected.txt\",sep='\\t', names=header_names)\n",
        "df3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tMrMnXVu0RF"
      },
      "source": [
        "data = pd.concat([df1, df2, df3], axis=0)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSzOprNyvyMj"
      },
      "source": [
        "data.to_csv('ner_dataset_id.txt', sep='\\t', mode='a', index=None, header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evI26Olf2dEZ"
      },
      "source": [
        "# Create a filename variable that holds the dataset ner\n",
        "filename = 'ner_dataset_id.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfp_VT3t3EKp"
      },
      "source": [
        "# Make a sentence id based on the sentence not based on the word\n",
        "def get_ner_data(filename):\n",
        "    word_list = []\n",
        "    sentence_counter = 0\n",
        "    with open(filename) as fp:\n",
        "        for cnt, line in enumerate(fp):\n",
        "            try:\n",
        "                texts = line.split()\n",
        "                if len(texts) != 0:\n",
        "                    word, label = ' '.join(texts[0:-1]), texts[-1]\n",
        "                    word_list.append([sentence_counter, word, label])\n",
        "                else:\n",
        "                    sentence_counter += 1\n",
        "            except:\n",
        "                print(\"Unexpected error:\", sys.exc_info()[0], cnt, line)\n",
        "                word_list.append([sentence_counter, \"\", \"\"])              \n",
        "                sentence_counter += 1\n",
        "                pass\n",
        "    print(f'read {cnt} lines')\n",
        "    ner_data = pd.DataFrame(word_list, columns=[\"sentence_id\", \"words\", \"labels\"])\n",
        "    return ner_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCdVBrXQ3Ht4",
        "outputId": "94a2160e-6857-479b-d410-ade5b28b1102"
      },
      "source": [
        "# Execute the get_ner_data function on the ner dataset\n",
        "df_data = get_ner_data(filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "read 452937 lines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "Q5Q9ju4X3N1O",
        "outputId": "b4e76a55-891a-45a6-ad1f-9abd067c8938"
      },
      "source": [
        "# Display the result of the function get_ner_data\n",
        "df_data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>words</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>mengekspor</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>produk</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>industri</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>skala</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>besar</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>ke</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>Indonesia</td>\n",
              "      <td>B-GPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>Amerika</td>\n",
              "      <td>B-GPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>Serikat</td>\n",
              "      <td>I-GPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_id       words labels\n",
              "0            0  mengekspor      O\n",
              "1            0      produk      O\n",
              "2            0    industri      O\n",
              "3            0       skala      O\n",
              "4            0       besar      O\n",
              "5            0          ke      O\n",
              "6            0   Indonesia  B-GPE\n",
              "7            0     Amerika  B-GPE\n",
              "8            0     Serikat  I-GPE\n",
              "9            0           .      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTbldVOLIhna",
        "outputId": "ae8475c9-581f-42e4-b5ff-bf51dd2cb5c5"
      },
      "source": [
        "# Count the amount of data in the value column labels\n",
        "df_data.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        303627\n",
              "I-DAT     13656\n",
              "B-PER      9524\n",
              "B-GPE      9087\n",
              "I-NOR      8201\n",
              "I-ORG      7063\n",
              "I-PER      6357\n",
              "B-PRD      5807\n",
              "I-PRD      5744\n",
              "B-NOR      5638\n",
              "B-CRD      5609\n",
              "B-ORG      5583\n",
              "I-LOC      5569\n",
              "B-DAT      5156\n",
              "I-MON      4236\n",
              "B-LOC      3486\n",
              "I-QTY      3266\n",
              "I-GPE      3225\n",
              "I-TIM      3048\n",
              "I-EVT      2937\n",
              "I-PRC      2248\n",
              "I-CRD      2228\n",
              "B-QTY      2078\n",
              "I-LAW      1958\n",
              "B-EVT      1779\n",
              "B-MON      1719\n",
              "I-FAC      1222\n",
              "B-PRC      1131\n",
              "B-TIM      1059\n",
              "B-ORD       815\n",
              "B-FAC       622\n",
              "B-REG       453\n",
              "B-LAW       431\n",
              "I-WOA       386\n",
              "I-REG       226\n",
              "B-WOA       208\n",
              "I-ORD        52\n",
              "B-LAN        13\n",
              "I-LAN        12\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtSzF9YeIkUa"
      },
      "source": [
        "# Retrieve sentences with their labels.\n",
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"words\"].values.tolist(),\n",
        "                                                     s[\"labels\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"sentence_id\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNJfTYO_Im8u",
        "outputId": "b9db876f-e141-4e58-c2fe-ede9ec8fe2f8"
      },
      "source": [
        "# Displays an example sentence on the first data\n",
        "getter = SentenceGetter(df_data)\n",
        "sentences = [[s[0] for s in sent] for sent in getter.sentences]\n",
        "print(sentences[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['mengekspor', 'produk', 'industri', 'skala', 'besar', 'ke', 'Indonesia', 'Amerika', 'Serikat', '.', 'Ekspor', 'dilakukan', 'melalui', 'Pelabuhan', 'Tanjung', 'Priok', ',', 'Jakarta', 'Utara', ',', 'Selasa', '(', '15', '/', '8', '/', '2018', ')', '.', 'Komoditas', 'yang', 'dikirim', 'terdiri', 'dari', '50', 'persen', 'sepatu', ',', '15', 'persen', 'garmen', ',', '10', 'persen', 'produk', 'karet', ',', 'ban', 'dan', 'turunannya', ',', 'alat', '-', 'alat', 'elektronik', '10', 'persen', ',', 'dan', 'produk', 'lainnya', '15', 'persen', '.', '\"', 'Bukan', 'bahan', 'mentah', ',', 'tetapi', 'sudah', 'bahan', '-', 'bahan', 'produksi', ',', 'produk', '-', 'produk', 'industri', 'yang', 'kita', 'harapkan', 'ini', 'akan', 'meningkatkan', 'ekspor', 'kita', ',', '\"', 'kata', 'Presiden', 'dalam', 'sambutannya', 'pada', 'acara', 'pelepasan', 'ekspor', 'di', 'Jakarta', 'International', 'Container', 'Terminal', '(', 'JICT', ')', ',', 'Selasa', '(', '15', '/', '5', '/', '2018', ')', '.', 'Ekspor', 'tersebut', 'menggunakan', 'Kapal', 'MV', 'CMA', 'CGM', 'Tage', '.', 'Kapal', 'ini', 'merupakan', 'kapal', 'besar', 'berkapasitas', '10', 'ribu', 'TEUs', 'dan', 'berbobot', '95.263', 'GT', '(', 'Gross', 'Tonnage', ')', '.', 'Kapal', 'ini', 'memiliki', 'layanan', 'Java', '-', 'America', 'Express', '(', 'JAX', ')', 'yang', 'rutin', 'melayani', 'rute', 'Pelabuhan', 'Tanjung', 'Priok', 'ke', 'West', 'Coast', '(', 'LA', 'dan', 'Oakland', ')', 'Amerika', 'Serikat', '(', 'direct', 'call', ')', '.', '\"', 'Artinya', 'pengiriman', 'ini', 'besar', 'sekali', 'dan', 'dilakukan', 'dengan', 'sangat', 'efisien', 'dengan', 'direct', 'call', '.', 'Ini', 'akan', 'menurunkan', 'biaya', 'logistik', 'yang', 'sangat', 'besar', '.', 'Tadi', 'sudah', 'disampaikan', 'oleh', 'Dirut', 'Pelindo', 'bahwa', 'setiap', 'kontainer', 'menghemat', 'biaya', 'kurang', 'lebih', 'USD', '300', 'dan', 'ini', 'akan', 'memberikan', 'daya', 'saing', 'produk', '-', 'produk', 'kita', 'terhadap', 'produk', '-', 'produk', 'dari', 'negara', 'lain', ',', '\"', 'lanjutnya', '.', 'Presiden', 'juga', 'menyampaikan', 'bahwa', 'ekspor', 'ke', 'Amerika', 'Serikat', 'ini', 'menandakan', 'bahwa', 'Indonesia', 'memiliki', 'peran', 'yang', 'sangat', 'strategis', 'dalam', 'geo', 'ekonomi', 'di', 'Indo', 'Pasifik', '.', 'Indonesia', 'berusaha', 'menjadikan', 'kawasan', 'Indo', 'Pasifik', 'sebagai', 'salah', 'satu', 'sumber', 'utama', 'pertumbuhan', 'ekonomi', ',', 'pusat', 'perdagangan', ',', 'dan', 'industri', 'dunia', '.', 'Turut', 'hadir', 'mendampingi', 'Presiden', 'dalam', 'pelepasan', 'ekspor', 'ini', 'adalah', 'Menteri', 'Perhubungan', 'Budi', 'Karya', 'Sumadi', ',', 'Menteri', 'Perindustrian', 'Airlangga', 'Hartarto', ',', 'Menteri', 'Perdagangan', 'Enggartiasto', 'Lukita', ',', 'Menteri', 'BUMN', 'Rini', 'Soemarno', 'dan', 'Direktur', 'Utama', 'IPC', 'Elvyn', 'G', '.', 'Masassya', '.', 'Polri', 'Awasi', 'Peredaran', 'Bahan', 'Bom', \"'\", 'The', 'Mother', 'of', 'Satan', \"'\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoUsAQ-GIod_",
        "outputId": "a2091060-992d-47f5-b6b7-ec3c83f72b41"
      },
      "source": [
        "# Displays an example of a Tag label on the first data\n",
        "labels = [[s[1] for s in sent] for sent in getter.sentences]\n",
        "print(labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'B-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O', 'B-GPE', 'I-GPE', 'O', 'B-DAT', 'O', 'I-DAT', 'O', 'I-DAT', 'O', 'I-DAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PRC', 'I-PRC', 'B-PRD', 'O', 'B-PRC', 'I-PRC', 'B-PRD', 'O', 'B-PRC', 'I-PRC', 'O', 'B-PRD', 'O', 'B-PRD', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PRC', 'I-PRC', 'O', 'O', 'O', 'O', 'B-PRC', 'I-PRC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'O', 'B-LOC', 'O', 'O', 'B-DAT', 'O', 'I-DAT', 'O', 'I-DAT', 'O', 'I-DAT', 'O', 'O', 'O', 'O', 'O', 'B-PRD', 'I-PRD', 'I-PRD', 'I-PRD', 'I-PRD', 'O', 'O', 'O', 'O', 'B-PRD', 'O', 'O', 'B-QTY', 'I-QTY', 'I-QTY', 'O', 'O', 'B-QTY', 'I-QTY', 'O', 'B-QTY', 'I-QTY', 'O', 'O', 'B-PRD', 'O', 'O', 'O', 'B-PRD', 'O', 'I-PRD', 'I-PRD', 'O', 'B-PRD', 'O', 'O', 'O', 'O', 'O', 'B-FAC', 'I-FAC', 'I-FAC', 'O', 'B-LOC', 'I-LOC', 'O', 'B-GPE', 'O', 'B-GPE', 'O', 'B-GPE', 'I-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORD', 'O', 'O', 'B-PRD', 'O', 'O', 'O', 'O', 'B-MON', 'I-MON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'I-GPE', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-GPE', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'B-NOR', 'I-NOR', 'B-PER', 'I-PER', 'I-PER', 'O', 'B-NOR', 'I-NOR', 'B-PER', 'I-PER', 'O', 'B-NOR', 'I-NOR', 'B-PER', 'I-PER', 'O', 'B-NOR', 'I-NOR', 'B-PER', 'I-PER', 'O', 'O', 'O', 'B-ORG', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'O', 'B-NOR', 'O', 'O', 'B-PRD', 'I-PRD', 'O', 'B-PRD', 'I-PRD', 'I-PRD', 'I-PRD', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBB3cPI_Ixlw"
      },
      "source": [
        "# Create a variable tags_vals = a variable that holds the labels column data in the form of a list\n",
        "tags_vals = list(set(df_data[\"labels\"].values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-OKlItMIyTZ"
      },
      "source": [
        "# Add the letter X to the tags_vals variable, then add an index to each label\n",
        "tags_vals.append('X')\n",
        "tag2idx = {t: i for i, t in enumerate(tags_vals)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbLeD68r_xPD",
        "outputId": "d5182dbf-c50b-429c-daa4-ed534a293173"
      },
      "source": [
        "tags_vals"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'I-NOR',\n",
              " 'B-ORD',\n",
              " 'B-PER',\n",
              " 'B-NOR',\n",
              " 'B-REG',\n",
              " 'B-LAN',\n",
              " 'I-LAW',\n",
              " 'I-DAT',\n",
              " 'I-PRD',\n",
              " 'I-GPE',\n",
              " 'I-LAN',\n",
              " 'I-WOA',\n",
              " 'I-MON',\n",
              " 'B-ORG',\n",
              " 'B-PRD',\n",
              " 'B-EVT',\n",
              " 'B-PRC',\n",
              " 'I-ORG',\n",
              " 'I-EVT',\n",
              " 'I-PRC',\n",
              " 'B-LOC',\n",
              " 'B-QTY',\n",
              " 'I-ORD',\n",
              " 'B-TIM',\n",
              " 'I-FAC',\n",
              " 'I-QTY',\n",
              " 'B-GPE',\n",
              " 'B-FAC',\n",
              " 'B-CRD',\n",
              " 'B-WOA',\n",
              " 'B-LAW',\n",
              " 'I-PER',\n",
              " 'I-LOC',\n",
              " 'I-CRD',\n",
              " 'B-DAT',\n",
              " 'I-REG',\n",
              " 'B-MON',\n",
              " 'I-TIM',\n",
              " 'X']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAAk5N_IJ-99",
        "outputId": "19a3f4cb-85ca-4330-a0c2-a88918569ba8"
      },
      "source": [
        "# View index results on tag data\n",
        "tag2idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-CRD': 29,\n",
              " 'B-DAT': 35,\n",
              " 'B-EVT': 16,\n",
              " 'B-FAC': 28,\n",
              " 'B-GPE': 27,\n",
              " 'B-LAN': 6,\n",
              " 'B-LAW': 31,\n",
              " 'B-LOC': 21,\n",
              " 'B-MON': 37,\n",
              " 'B-NOR': 4,\n",
              " 'B-ORD': 2,\n",
              " 'B-ORG': 14,\n",
              " 'B-PER': 3,\n",
              " 'B-PRC': 17,\n",
              " 'B-PRD': 15,\n",
              " 'B-QTY': 22,\n",
              " 'B-REG': 5,\n",
              " 'B-TIM': 24,\n",
              " 'B-WOA': 30,\n",
              " 'I-CRD': 34,\n",
              " 'I-DAT': 8,\n",
              " 'I-EVT': 19,\n",
              " 'I-FAC': 25,\n",
              " 'I-GPE': 10,\n",
              " 'I-LAN': 11,\n",
              " 'I-LAW': 7,\n",
              " 'I-LOC': 33,\n",
              " 'I-MON': 13,\n",
              " 'I-NOR': 1,\n",
              " 'I-ORD': 23,\n",
              " 'I-ORG': 18,\n",
              " 'I-PER': 32,\n",
              " 'I-PRC': 20,\n",
              " 'I-PRD': 9,\n",
              " 'I-QTY': 26,\n",
              " 'I-REG': 36,\n",
              " 'I-TIM': 38,\n",
              " 'I-WOA': 12,\n",
              " 'O': 0,\n",
              " 'X': 39}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw_Z-rMhKEn1"
      },
      "source": [
        "# Mapping index to name\n",
        "tag2name={tag2idx[key] : key for key in tag2idx.keys()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9SWEO27KGdx"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BH7kgQSKINn",
        "outputId": "2e7a9ef4-7c5c-488c-eeab-814790a176d7"
      },
      "source": [
        "n_gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QumP84MVKJvt"
      },
      "source": [
        "# Len sentences must be the same as the training model\n",
        "# See 'max_position_embeddings' = 512\n",
        "max_len  = 45\n",
        "\n",
        "# load tokenizer, with manual file address or pretrained address\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLcV4s95KL5a"
      },
      "source": [
        "def tokenize_and_preserve_labels(sentence, text_labels):\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    for word, label in zip(sentence, text_labels):\n",
        "\n",
        "        # Tokenize words and count the number of subwords broken into words\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add tokenized word to tokenized last word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the list of new labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQl04eKMKeh6"
      },
      "source": [
        "tokenized_texts_and_labels = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in zip(sentences, labels)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-HA5ORWKg67"
      },
      "source": [
        "tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
        "\n",
        "labels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUGAb7_HKmfG",
        "outputId": "375dfdcf-1944-4b24-8c85-99ee0dc2fb5c"
      },
      "source": [
        "# Make text token id\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "print(input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[27955  5937 13102  2953  4013 28351 27746 18886 24053  2721  2022 10286\n",
            " 17710  6239  2572 27350  2050 14262  7556  2102  1012 23969 13102  2953\n",
            " 29454  4817 15750  2078 11463  2389 10179 21877 20470 27225  2319  9092\n",
            " 19792  2290 26927  6559  1010 14426 28981  2527  1010]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYxrAX_YKqLH",
        "outputId": "f75f34ac-3bb0-41c8-f575-ef3133e6d906"
      },
      "source": [
        "# Make label to be id, pad with \"O\" which means other\n",
        "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
        "                     maxlen=max_len, value=tag2idx[\"X\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "print(tags[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0 27 27 27 27 10 10 10  0  0  0  0\n",
            "  0  0  0  0  0  0  0 28 28 28 28 25 25 25 25 25  0 27 10 10  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSDgB0WYKsMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb1ae2ba-879e-45d3-8f8c-7d9e7c2360d6"
      },
      "source": [
        "# For prediction accuracy, with token mask is 1, token pad is 0\n",
        "attention_masks = [[int(i>0) for i in ii] for ii in input_ids]\n",
        "attention_masks[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIZNVM5JLSbU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faff0607-7202-4027-8e3e-04d7021f6d41"
      },
      "source": [
        "# Because it is only one sentence, all segments are set to 0\n",
        "segment_ids = [[0] * len(input_id) for input_id in input_ids]\n",
        "segment_ids[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdblVUpILUYj"
      },
      "source": [
        "# Divide the dataset into train and val\n",
        "tr_inputs, val_inputs, tr_tags, val_tags,tr_masks, val_masks,tr_segs, val_segs = train_test_split(input_ids, tags,attention_masks,segment_ids, \n",
        "                                                                                                  random_state=4, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGXxZ44xLZCE"
      },
      "source": [
        "# Create a dataset that has been divided into train and val data into tensor form\n",
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)\n",
        "tr_segs = torch.tensor(tr_segs)\n",
        "val_segs = torch.tensor(val_segs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuhNzUgCL9IM"
      },
      "source": [
        "# Set batch_num size\n",
        "batch_num = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz1I0MybL-_o"
      },
      "source": [
        "# Set only token embed, attention pinned, no segment embed\n",
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "# Drop last dapat membuat pelatihan batch lebih baik untuk yang terakhir\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_num,drop_last=True)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6crusZdMBJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b2b059-df47-45dc-cce6-d2a17c18cecb"
      },
      "source": [
        "# Run the BertForTokenClassification model using a pretrained bert-base-uncased, with a number of num labels based on the number of tag ids\n",
        "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\",num_labels=len(tag2idx))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv7En65kMDP-",
        "outputId": "d0d0ac8a-39ce-4c47-d9cf-34d5951ef174"
      },
      "source": [
        "# Running model using cuda model\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=40, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5jM8FyILINC",
        "outputId": "4f147cd9-4cc5-4f7e-af72-12796692a567"
      },
      "source": [
        "# Get all model parameters in a list of tuples\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 199 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.encoder.layer.11.output.LayerNorm.weight                 (768,)\n",
            "bert.encoder.layer.11.output.LayerNorm.bias                   (768,)\n",
            "classifier.weight                                          (40, 768)\n",
            "classifier.bias                                                (40,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKKmJFB7MGhA"
      },
      "source": [
        "# Add multi GPU support\n",
        "if n_gpu >1:\n",
        "    model = torch.nn.DataParallel(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b35jHLBGMODt"
      },
      "source": [
        "# True: fine-tune all layers\n",
        "# False: only enhances the classifier layer\n",
        "FULL_FINETUNING = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdEhjt8cMP2N"
      },
      "source": [
        "if FULL_FINETUNING:\n",
        "    # Fine-tune the model of all layer parameters\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}]\n",
        "else:\n",
        "    # Only fine tune classifier parameters\n",
        "    param_optimizer = list(model.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPZ8zLaEMI_A"
      },
      "source": [
        "# Set epoch and grad max num\n",
        "epochs = 5\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "# The total number of training steps is the number of batches * the number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create a learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVPwSi6NSyou",
        "outputId": "2b67d9a6-519c-435a-88fa-de6cc6f35950"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Save the loss value and validation loss value for each epoch so you can plot them.\n",
        "loss_values, validation_loss_values = [], []\n",
        "\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    # Perform one full pass over the exercise set.\n",
        "\n",
        "    # Put the model into training mode.\n",
        "    model.train()\n",
        "    # Reset total loss.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Training loop\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Always clear pre-calculated gradients before performing backwards passes.\n",
        "        model.zero_grad()\n",
        "        # Forward feed   \n",
        "        # This will return loss (not model output)\n",
        "        # Because it has provided `label`.\n",
        "        outputs = model(b_input_ids, token_type_ids=None,\n",
        "                        attention_mask=b_input_mask, labels=b_labels)\n",
        "        # Get loss value\n",
        "        loss = outputs[0]\n",
        "        # Perform a backward motion to calculate the gradient.\n",
        "        loss.backward()\n",
        "        # Track the value of train loss\n",
        "        total_loss += loss.item()       \n",
        "        # Gradient norm clip\n",
        "        # This is to help prevent \"gradient explosion\" issues.\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        # Update parameter\n",
        "        optimizer.step()\n",
        "        # Update learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    \n",
        "    # Calculate the average loss of training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(\"Average train loss: {}\".format(avg_train_loss))\n",
        "\n",
        "    # Save the result of the loss training value obtained\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After completing each training period, measure the performance of the validation set.\n",
        "\n",
        "    # Put the model into evaluation mode\n",
        "    model.eval()\n",
        "    # Reset validation loss\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in valid_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Tells the model not to calculate or save gradients,\n",
        "        # save memory and speed up validation\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit prediction.\n",
        "            # This will return a log instead of a loss because it has not provided a label.\n",
        "            outputs = model(b_input_ids, token_type_ids=None,\n",
        "                            attention_mask=b_input_mask, labels=b_labels)\n",
        "        \n",
        "        # Move logs and labels to CPU\n",
        "        logits = outputs[1].detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        eval_loss += outputs[0].mean().item()\n",
        "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "        true_labels.extend(label_ids)\n",
        "\n",
        "    eval_loss = eval_loss / len(valid_dataloader)\n",
        "    validation_loss_values.append(eval_loss)\n",
        "    print(\"Validation loss: {}\".format(eval_loss))\n",
        "   \n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average train loss: 0.8618221553577774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|â–ˆâ–ˆ        | 1/5 [02:05<08:22, 125.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4769434576187659\n",
            "\n",
            "Average train loss: 0.4008863110651915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [04:18<06:23, 127.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.34113697160821443\n",
            "\n",
            "Average train loss: 0.2732286398609479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [06:31<04:18, 129.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.2959327167327251\n",
            "\n",
            "Average train loss: 0.20920894855055316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [08:45<02:10, 130.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.2889885064385353\n",
            "\n",
            "Average train loss: 0.173656714407877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [10:59<00:00, 131.84s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.2834860639424499\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "PlycdFBLVz0Y",
        "outputId": "292efa88-935f-4ed2-beff-2e1e0556965c"
      },
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o', label=\"training loss\")\n",
        "plt.plot(validation_loss_values, 'r-o', label=\"validation loss\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Learning curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yxGJ3a_VVX0"
      },
      "source": [
        "# Create a variable that will hold the model results and save it in a folder\n",
        "bert_out_address = 'models/bert_out_model/id'\n",
        "# Create self if not exit\n",
        "if not os.path.exists(bert_out_address):\n",
        "        os.makedirs(bert_out_address)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x635uMX7VYta"
      },
      "source": [
        "model_to_save = model.module if hasattr(model, 'module') else model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szf7ZfW0VZg-",
        "outputId": "ec2f4a14-81bb-4b2b-e90c-163f0ccbb714"
      },
      "source": [
        "# If we save using a predefined name, we can load using `from_pretrained`\n",
        "output_model_file = os.path.join(bert_out_address, \"pytorch_model.bin\")\n",
        "output_config_file = os.path.join(bert_out_address, \"config.json\")\n",
        "\n",
        "# Save model into file\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "model_to_save.config.to_json_file(output_config_file)\n",
        "tokenizer.save_vocabulary(bert_out_address)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('models/bert_out_model/id/vocab.txt',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YIl2wsnVbo9"
      },
      "source": [
        "# Rerun the model but use pretrained from the previously saved training model\n",
        "model = BertForTokenClassification.from_pretrained(bert_out_address,num_labels=len(tag2idx))\n",
        "\n",
        "model.cuda(); # Set model ke GPU\n",
        "\n",
        "if n_gpu >1:\n",
        "    model = torch.nn.DataParallel(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCO5AWiqVeZS",
        "outputId": "3b571fa5-2df9-4916-d723-bc366673adbd"
      },
      "source": [
        "# Evaluate the model\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=40, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdmfgqj1VgYt",
        "outputId": "43df94e4-58dd-440b-d151-480b4e790c1a"
      },
      "source": [
        "print(\"***** Running evaluation *****\")\n",
        "print(\"  Num examples ={}\".format(len(val_inputs)))\n",
        "print(\"  Batch size = {}\".format(batch_num))\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for batch in (valid_dataloader):\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  with torch.no_grad():\n",
        "      outputs = model(b_input_ids, token_type_ids=None,\n",
        "      attention_mask=b_input_mask,labels=b_labels)\n",
        "      \n",
        "      # For evaluation mode, the first result of the output is logits\n",
        "      logits = outputs[1] \n",
        "  \n",
        "  # Get NER prediction results\n",
        "  logits = torch.argmax(F.log_softmax(logits,dim=2),dim=2)\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  \n",
        "  \n",
        "  # Get real NER results\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Only predict the actual word, mark = 0, will not count\n",
        "  input_mask = b_input_mask.to('cpu').numpy()\n",
        "  \n",
        "  # Compare valuable prediction results\n",
        "  for i,mask in enumerate(input_mask):\n",
        "      # temp_1 for actual data\n",
        "      temp_1 = []\n",
        "      # temp_2 for prediction result data\n",
        "      temp_2 = []\n",
        "      \n",
        "      for j, m in enumerate(mask):\n",
        "          # Mark = 0, it means it's pad word, don't compare\n",
        "          if m:\n",
        "              if tag2name[label_ids[i][j]] != \"X\": # Exclude label X\n",
        "                  temp_1.append(tag2name[label_ids[i][j]])\n",
        "                  temp_2.append(tag2name[logits[i][j]])\n",
        "          else:\n",
        "              break\n",
        "      \n",
        "          \n",
        "      y_true.append(temp_1)\n",
        "      y_pred.append(temp_2)\n",
        "\n",
        "\n",
        "print(\"f1 socre: %f\"%(f1_score(y_true, y_pred)))\n",
        "print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
        "\n",
        "# Get acc, recall, report F1 results\n",
        "report = classification_report(y_true, y_pred,digits=4)\n",
        "\n",
        "# Save report into file\n",
        "output_eval_file = os.path.join(bert_out_address, \"eval_results.txt\")\n",
        "with open(output_eval_file, \"w\") as writer:\n",
        "  print(\"***** Eval results *****\")\n",
        "  print(\"\\n%s\"%(report))\n",
        "  print(\"f1 socre: %f\"%(f1_score(y_true, y_pred)))\n",
        "  print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
        "  \n",
        "  writer.write(\"f1 socre:\\n\")\n",
        "  writer.write(str(f1_score(y_true, y_pred)))\n",
        "  writer.write(\"\\n\\nAccuracy score:\\n\")\n",
        "  writer.write(str(accuracy_score(y_true, y_pred)))\n",
        "  writer.write(\"\\n\\n\")  \n",
        "  writer.write(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running evaluation *****\n",
            "  Num examples =3486\n",
            "  Batch size = 32\n",
            "f1 socre: 0.748082\n",
            "Accuracy score: 0.926134\n",
            "***** Eval results *****\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         CRD     0.7859    0.8711    0.8263      1218\n",
            "         DAT     0.9155    0.9357    0.9255      1088\n",
            "         EVT     0.6259    0.6121    0.6189       593\n",
            "         FAC     0.5060    0.3853    0.4375       218\n",
            "         GPE     0.8171    0.8624    0.8392      2777\n",
            "         LAN     0.0000    0.0000    0.0000         8\n",
            "         LAW     0.4125    0.2426    0.3056       136\n",
            "         LOC     0.5059    0.5537    0.5287      1015\n",
            "         MON     0.9206    0.9627    0.9412       482\n",
            "         NOR     0.7228    0.8085    0.7633      2235\n",
            "         ORD     0.7702    0.7490    0.7594       255\n",
            "         ORG     0.6409    0.6471    0.6440      1961\n",
            "         PER     0.8534    0.8626    0.8580      2903\n",
            "         PRC     0.9485    0.8897    0.9181       145\n",
            "         PRD     0.5645    0.5745    0.5695      1873\n",
            "         QTY     0.6675    0.6798    0.6736       381\n",
            "         REG     0.4152    0.4702    0.4410       151\n",
            "         TIM     0.9333    0.9032    0.9180       186\n",
            "         WOA     0.0909    0.0169    0.0286        59\n",
            "\n",
            "   micro avg     0.7357    0.7609    0.7481     17684\n",
            "   macro avg     0.6367    0.6330    0.6314     17684\n",
            "weighted avg     0.7325    0.7609    0.7457     17684\n",
            "\n",
            "f1 socre: 0.748082\n",
            "Accuracy score: 0.926134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7eTp-cz3Fi4"
      },
      "source": [
        "test_sentence = \"\"\"\n",
        "Berdasarkan data Badan Penelitian dan Pengembangan Kesehatan (Balitbangkes) ada 1.118 kasus Covid-19 dengan varian Delta di Indonesia hingga 29 Juli 2021. Hasil penelitian spesimen menunjukkan, varian Delta virus corona telah menyebar hampir merata di seluruh wilayah di Indonesia. Direktur Pencegahan dan Pengendalian Penyakit Menular Langsung Kementerian Kesehatan (Kemenkes) Siti Nadia Tarmizi membenarkan hal tersebut. \"Varian Delta mendominasi 86 persen spesimen yang dilakukan sequencing dalam 60 hari terakhir, berasal dari 24 provinsi, sehingga dapat dikatakan persebaran ini hampir merata di seluruh Indonesia,\" kata Nadia, dikutip dari Antara, Minggu (1/8/2021). Jejaring laboratorium genomic sequencing atau metode pengurutan memetakan mutasi virus, terus berupaya menelusuri pola persebaran varian virus corona di Indonesia.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FZ8oU1q3VvX"
      },
      "source": [
        "tokenized_sentence = tokenizer.encode(test_sentence)\n",
        "input_ids = torch.tensor([tokenized_sentence]).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NhsqJVn3ZWH"
      },
      "source": [
        "with torch.no_grad():\n",
        "    output = model(input_ids)\n",
        "label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjRcnkh-20UZ",
        "outputId": "f814c935-e58c-4b19-dfeb-0fd20bf99725"
      },
      "source": [
        "# join  split tokens\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
        "new_tokens, new_labels = [], []\n",
        "for token, label_idx in zip(tokens, label_indices[0]):\n",
        "    if token.startswith(\"##\"):\n",
        "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "    else:\n",
        "        new_labels.append(tags_vals[label_idx])\n",
        "        new_tokens.append(token)\n",
        "\n",
        "for token, label in zip(new_tokens, new_labels):\n",
        "    print(\"{}\\t{}\".format(label, token))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\t[CLS]\n",
            "O\tberdasarkan\n",
            "O\tdata\n",
            "O\tbadan\n",
            "O\tpenelitian\n",
            "O\tdan\n",
            "O\tpengembangan\n",
            "O\tkesehatan\n",
            "O\t(\n",
            "O\tbalitbangkes\n",
            "O\t)\n",
            "O\tada\n",
            "B-CRD\t1\n",
            "I-CRD\t.\n",
            "I-CRD\t118\n",
            "O\tkasus\n",
            "O\tcovid\n",
            "O\t-\n",
            "B-CRD\t19\n",
            "O\tdengan\n",
            "O\tvarian\n",
            "O\tdelta\n",
            "O\tdi\n",
            "B-GPE\tindonesia\n",
            "O\thingga\n",
            "B-DAT\t29\n",
            "I-DAT\tjuli\n",
            "I-DAT\t2021\n",
            "O\t.\n",
            "O\thasil\n",
            "O\tpenelitian\n",
            "O\tspesimen\n",
            "O\tmenunjukkan\n",
            "O\t,\n",
            "O\tvarian\n",
            "O\tdelta\n",
            "O\tvirus\n",
            "O\tcorona\n",
            "O\ttelah\n",
            "O\tmenyebar\n",
            "O\thampir\n",
            "O\tmerata\n",
            "O\tdi\n",
            "O\tseluruh\n",
            "O\twilayah\n",
            "O\tdi\n",
            "B-GPE\tindonesia\n",
            "O\t.\n",
            "O\tdirektur\n",
            "O\tpencegahan\n",
            "O\tdan\n",
            "O\tpengendalian\n",
            "O\tpenyakit\n",
            "O\tmenular\n",
            "O\tlangsung\n",
            "B-NOR\tkementerian\n",
            "I-NOR\tkesehatan\n",
            "O\t(\n",
            "B-NOR\tkemenkes\n",
            "O\t)\n",
            "B-PER\tsiti\n",
            "B-PER\tnadia\n",
            "I-PER\ttarmizi\n",
            "O\tmembenarkan\n",
            "O\thal\n",
            "O\ttersebut\n",
            "O\t.\n",
            "O\t\"\n",
            "O\tvarian\n",
            "O\tdelta\n",
            "O\tmendominasi\n",
            "B-PRC\t86\n",
            "I-PRC\tpersen\n",
            "O\tspesimen\n",
            "O\tyang\n",
            "O\tdilakukan\n",
            "O\tsequencing\n",
            "O\tdalam\n",
            "B-QTY\t60\n",
            "I-QTY\thari\n",
            "O\tterakhir\n",
            "O\t,\n",
            "O\tberasal\n",
            "O\tdari\n",
            "B-CRD\t24\n",
            "O\tprovinsi\n",
            "O\t,\n",
            "O\tsehingga\n",
            "O\tdapat\n",
            "O\tdikatakan\n",
            "O\tpersebaran\n",
            "O\tini\n",
            "O\thampir\n",
            "O\tmerata\n",
            "O\tdi\n",
            "O\tseluruh\n",
            "B-GPE\tindonesia\n",
            "O\t,\n",
            "O\t\"\n",
            "O\tkata\n",
            "B-PER\tnadia\n",
            "O\t,\n",
            "O\tdikutip\n",
            "O\tdari\n",
            "O\tantara\n",
            "O\t,\n",
            "B-DAT\tminggu\n",
            "O\t(\n",
            "B-DAT\t1\n",
            "I-DAT\t/\n",
            "I-DAT\t8\n",
            "I-DAT\t/\n",
            "I-DAT\t2021\n",
            "O\t)\n",
            "O\t.\n",
            "O\tjejaring\n",
            "O\tlaboratorium\n",
            "O\tgenomic\n",
            "O\tsequencing\n",
            "O\tatau\n",
            "O\tmetode\n",
            "O\tpengurutan\n",
            "O\tmemetakan\n",
            "O\tmutasi\n",
            "O\tvirus\n",
            "O\t,\n",
            "O\tterus\n",
            "O\tberupaya\n",
            "O\tmenelusuri\n",
            "O\tpola\n",
            "O\tpersebaran\n",
            "O\tvarian\n",
            "O\tvirus\n",
            "O\tcorona\n",
            "O\tdi\n",
            "B-GPE\tindonesia\n",
            "O\t.\n",
            "O\t[SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B1NbyOFvOgr",
        "outputId": "f8275e89-805e-4412-8e03-031030d102b4"
      },
      "source": [
        "!huggingface-cli login"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "        \n",
            "Username: liandarizkia\n",
            "Password: \n",
            "Login successful\n",
            "Your token: WbSjJfyKTADCvLVJnXWxtfySQRdZenFNiRqafZglFLKsDnqHnIQFwHIomCrCOvOmZMyPzzqADHCYqwbLvWPfYdsVvdtqaIRpYrOklwDxaeINumhjXPrxoqVeRXvDEUOw \n",
            "\n",
            "Your token has been saved to /root/.huggingface/token\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UHEAyHggwvG8",
        "outputId": "a616fae8-b0b0-49c0-ca3f-5f151015a7fd"
      },
      "source": [
        "from huggingface_hub import HfApi, HfFolder\n",
        "\n",
        "api = HfApi()\n",
        "folder = HfFolder()\n",
        "token = folder.get_token()\n",
        "\n",
        "api.create_repo(token, \"bert-id-ner\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://huggingface.co/liandarizkia/bert-id-ner'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "esuvpqVFw-RB",
        "outputId": "3c59e298-d0f6-4b75-916e-5d73edef488e"
      },
      "source": [
        "api.upload_file(token, path_or_fileobj=\"models/bert_out_model/id/pytorch_model.bin\", path_in_repo=\"pytorch_model.bin\", repo_id=\"liandarizkia/bert-id-ner\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://huggingface.co/liandarizkia/bert-id-ner/blob/main/pytorch_model.bin'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167,
          "referenced_widgets": [
            "acc38768d6e541928b6caf82a181aec2",
            "660bf95523514b6cace3881713f49872",
            "a2cea83034d94e4b9016603694f25f5f",
            "940602ec2c9b4fc4a98f254fa637a653",
            "bd73252594d746e8be8f7dd07681d9eb",
            "dc164f0034c646b7aeac112ede4e2320",
            "a986aa00401b40bea19522de9d267dff",
            "bf317bef6f2f418d8eb805c929ee7423",
            "e511ab98c8904326865d6478c0489481",
            "c3af902e8aa7493889784cb6c3c2ca74",
            "63d0283f28b8499b861084fe9a602f45",
            "4e3f5e8be2ac4421874c301900d1ae8f",
            "6dac786690fa4a4eb5fad0d51194e87c",
            "bb749ed3b91246169ba6866e12992560",
            "acc39389739145238931d45a84f3fe50",
            "b28562d92e504ac1b4f9496bac9124ed",
            "06e5f3939487493fb74ecda0d439186e",
            "cf951285060949b0b0a8e31ffbb0d051",
            "c7213bbe161140f4ad2554152f7442d2",
            "10d0d34cec8f4017a636612e3f49d73e",
            "17bbd3a08a6f4aa5a8420a4c1e22a46c",
            "20a63180826b4ad9892cee9434e3ac1f",
            "4773f274f20645a7b72ade09f25b544c",
            "42bf6d41ea864661b02d7771dd7a78be"
          ]
        },
        "id": "yBWdhDblyd34",
        "outputId": "c5a3dfb0-13b7-4148-e719-bfa4bf111f96"
      },
      "source": [
        "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"liandarizkia/bert-id-ner\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"liandarizkia/bert-id-ner\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acc38768d6e541928b6caf82a181aec2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2285.0, style=ProgressStyle(descriptionâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e511ab98c8904326865d6478c0489481",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435773041.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06e5f3939487493fb74ecda0d439186e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5eG8GhJzydB"
      },
      "source": [
        "label_list = [\n",
        " 'O',\n",
        " 'I-NOR',\n",
        " 'B-ORD',\n",
        " 'B-PER',\n",
        " 'B-NOR',\n",
        " 'B-REG',\n",
        " 'B-LAN',\n",
        " 'I-LAW',\n",
        " 'I-DAT',\n",
        " 'I-PRD',\n",
        " 'I-GPE',\n",
        " 'I-LAN',\n",
        " 'I-WOA',\n",
        " 'I-MON',\n",
        " 'B-ORG',\n",
        " 'B-PRD',\n",
        " 'B-EVT',\n",
        " 'B-PRC',\n",
        " 'I-ORG',\n",
        " 'I-EVT',\n",
        " 'I-PRC',\n",
        " 'B-LOC',\n",
        " 'B-QTY',\n",
        " 'I-ORD',\n",
        " 'B-TIM',\n",
        " 'I-FAC',\n",
        " 'I-QTY',\n",
        " 'B-GPE',\n",
        " 'B-FAC',\n",
        " 'B-CRD',\n",
        " 'B-WOA',\n",
        " 'B-LAW',\n",
        " 'I-PER',\n",
        " 'I-LOC',\n",
        " 'I-CRD',\n",
        " 'B-DAT',\n",
        " 'I-REG',\n",
        " 'B-MON',\n",
        " 'I-TIM',\n",
        " 'X'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8xYhe30XPOw"
      },
      "source": [
        "sequence = \"\"\"\n",
        "Berdasarkan data Badan Penelitian dan Pengembangan Kesehatan (Balitbangkes) ada 1.118 kasus Covid-19 dengan varian Delta di Indonesia hingga 29 Juli 2021. Hasil penelitian spesimen menunjukkan, varian Delta virus corona telah menyebar hampir merata di seluruh wilayah di Indonesia. Direktur Pencegahan dan Pengendalian Penyakit Menular Langsung Kementerian Kesehatan (Kemenkes) Siti Nadia Tarmizi membenarkan hal tersebut. \"Varian Delta mendominasi 86 persen spesimen yang dilakukan sequencing dalam 60 hari terakhir, berasal dari 24 provinsi, sehingga dapat dikatakan persebaran ini hampir merata di seluruh Indonesia,\" kata Nadia, dikutip dari Antara, Minggu (1/8/2021). Jejaring laboratorium genomic sequencing atau metode pengurutan memetakan mutasi virus, terus berupaya menelusuri pola persebaran varian virus corona di Indonesia.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXLnS-rj2nRy",
        "outputId": "85c4e78b-c670-4e32-e821-0d53dd174e5f"
      },
      "source": [
        "# Bit of a hack to get the tokens with the special tokens\n",
        "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n",
        "inputs = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model(inputs)[0]\n",
        "predictions = torch.argmax(outputs, dim=2)\n",
        "\n",
        "# print([(token, label_list[prediction]) for token, prediction in zip(tokens, predictions[0].tolist())])\n",
        "\n",
        "\n",
        "new_tokens, new_labels = [], []\n",
        "for token, label_idx in zip(tokens, predictions[0]):\n",
        "    if token.startswith(\"##\"):\n",
        "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "    else:\n",
        "        new_labels.append(label_list[label_idx])\n",
        "        new_tokens.append(token)\n",
        "\n",
        "for token, label in zip(new_tokens, new_labels):\n",
        "    print(\"{}\\t{}\".format(label, token))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\t[CLS]\n",
            "O\tberdasarkan\n",
            "O\tdata\n",
            "O\tbadan\n",
            "O\tpenelitian\n",
            "O\tdan\n",
            "O\tpengembangan\n",
            "O\tkesehatan\n",
            "O\t(\n",
            "O\tbalitbangkes\n",
            "O\t)\n",
            "O\tada\n",
            "B-CRD\t1\n",
            "I-CRD\t.\n",
            "I-CRD\t118\n",
            "O\tkasus\n",
            "O\tcovid\n",
            "O\t-\n",
            "B-CRD\t19\n",
            "O\tdengan\n",
            "O\tvarian\n",
            "O\tdelta\n",
            "O\tdi\n",
            "B-GPE\tindonesia\n",
            "O\thingga\n",
            "B-DAT\t29\n",
            "I-DAT\tjuli\n",
            "I-DAT\t2021\n",
            "O\t.\n",
            "O\thasil\n",
            "O\tpenelitian\n",
            "O\tspesimen\n",
            "O\tmenunjukkan\n",
            "O\t,\n",
            "O\tvarian\n",
            "O\tdelta\n",
            "O\tvirus\n",
            "O\tcorona\n",
            "O\ttelah\n",
            "O\tmenyebar\n",
            "O\thampir\n",
            "O\tmerata\n",
            "O\tdi\n",
            "O\tseluruh\n",
            "O\twilayah\n",
            "O\tdi\n",
            "B-GPE\tindonesia\n",
            "O\t.\n",
            "O\tdirektur\n",
            "O\tpencegahan\n",
            "O\tdan\n",
            "O\tpengendalian\n",
            "O\tpenyakit\n",
            "O\tmenular\n",
            "O\tlangsung\n",
            "B-NOR\tkementerian\n",
            "I-NOR\tkesehatan\n",
            "O\t(\n",
            "B-NOR\tkemenkes\n",
            "O\t)\n",
            "B-PER\tsiti\n",
            "B-PER\tnadia\n",
            "I-PER\ttarmizi\n",
            "O\tmembenarkan\n",
            "O\thal\n",
            "O\ttersebut\n",
            "O\t.\n",
            "O\t\"\n",
            "O\tvarian\n",
            "O\tdelta\n",
            "O\tmendominasi\n",
            "B-PRC\t86\n",
            "I-PRC\tpersen\n",
            "O\tspesimen\n",
            "O\tyang\n",
            "O\tdilakukan\n",
            "O\tsequencing\n",
            "O\tdalam\n",
            "B-QTY\t60\n",
            "I-QTY\thari\n",
            "O\tterakhir\n",
            "O\t,\n",
            "O\tberasal\n",
            "O\tdari\n",
            "B-CRD\t24\n",
            "O\tprovinsi\n",
            "O\t,\n",
            "O\tsehingga\n",
            "O\tdapat\n",
            "O\tdikatakan\n",
            "O\tpersebaran\n",
            "O\tini\n",
            "O\thampir\n",
            "O\tmerata\n",
            "O\tdi\n",
            "O\tseluruh\n",
            "B-GPE\tindonesia\n",
            "O\t,\n",
            "O\t\"\n",
            "O\tkata\n",
            "B-PER\tnadia\n",
            "O\t,\n",
            "O\tdikutip\n",
            "O\tdari\n",
            "O\tantara\n",
            "O\t,\n",
            "B-DAT\tminggu\n",
            "O\t(\n",
            "B-DAT\t1\n",
            "I-DAT\t/\n",
            "I-DAT\t8\n",
            "I-DAT\t/\n",
            "I-DAT\t2021\n",
            "O\t)\n",
            "O\t.\n",
            "O\tjejaring\n",
            "O\tlaboratorium\n",
            "O\tgenomic\n",
            "O\tsequencing\n",
            "O\tatau\n",
            "O\tmetode\n",
            "O\tpengurutan\n",
            "O\tmemetakan\n",
            "O\tmutasi\n",
            "O\tvirus\n",
            "O\t,\n",
            "O\tterus\n",
            "O\tberupaya\n",
            "O\tmenelusuri\n",
            "O\tpola\n",
            "O\tpersebaran\n",
            "O\tvarian\n",
            "O\tvirus\n",
            "O\tcorona\n",
            "O\tdi\n",
            "B-GPE\tindonesia\n",
            "O\t.\n",
            "O\t[SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2PECvqIrrRZ"
      },
      "source": [
        "!rm -rf models/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}